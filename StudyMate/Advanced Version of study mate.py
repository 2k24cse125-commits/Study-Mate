# -*- coding: utf-8 -*-
"""granite-3.3-2b-instruct.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//huggingface.co/ibm-granite/granite-3.3-2b-instruct.ipynb
"""

!pip install -U transformers

import gradio as gr
from transformers import pipeline
import PyPDF2
import json
import re
import os
from datetime import datetime
from typing import List, Tuple, Dict, Optional
import hashlib
import time
import numpy as np
from collections import defaultdict, Counter

class AdvancedStudentPDFQA:
    def __init__(self):
        print("ğŸš€ Initializing Advanced AI Study System...")
        print("ğŸ“š Loading Granite 3.3 2B Instruct Model...")

        # Initialize the AI pipeline
        self.pipe = pipeline("text-generation", model="ibm-granite/granite-3.3-2b-instruct")

        print("âœ… Model loaded successfully!")

        # Document storage and management
        self.documents = {}  # {doc_id: {title, content, metadata, chunks}}
        self.active_document = None
        self.document_embeddings = {}

        # Advanced learning features
        self.learning_progress = defaultdict(dict)  # {topic: {difficulty, mastery, attempts}}
        self.question_history = []
        self.weak_areas = defaultdict(int)
        self.study_sessions = []

        # Quiz and assessment system
        self.quiz_bank = {}
        self.assessment_results = []
        self.adaptive_difficulty = "medium"

        # Conversation and context management
        self.conversation_contexts = {}
        self.study_goals = []
        self.bookmarks = []

        # Performance analytics
        self.response_times = []
        self.question_types = Counter()
        self.topics_studied = Counter()

        print("ğŸ“ Advanced Study System Ready!")

    def upload_multiple_documents(self, files) -> Tuple[str, str]:
        """Process multiple PDF documents"""
        if not files:
            return "âŒ No files uploaded", ""

        processed_docs = []
        summary_text = "ğŸ“š *Document Library Summary*\n\n"

        try:
            for file in files:
                if file is None:
                    continue

                # Generate unique document ID
                doc_id = hashlib.md5(f"{file.name}{time.time()}".encode()).hexdigest()[:8]

                # Extract PDF content
                pdf_reader = PyPDF2.PdfReader(file)
                content = ""

                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    page_text = page.extract_text()
                    content += f"\n--- Page {page_num + 1} ---\n{page_text}"

                # Process document
                doc_title = os.path.basename(file.name).replace('.pdf', '')
                doc_chunks = self.chunk_document(content)

                # Store document
                self.documents[doc_id] = {
                    'title': doc_title,
                    'content': content,
                    'chunks': doc_chunks,
                    'upload_time': datetime.now(),
                    'pages': len(pdf_reader.pages),
                    'word_count': len(content.split()),
                    'topics': self.extract_topics(content)
                }

                processed_docs.append((doc_id, doc_title))

                # Add to summary
                doc_summary = self.generate_document_summary(content, doc_title)
                summary_text += f"### ğŸ“– {doc_title}\n"
                summary_text += f"- *Pages:* {len(pdf_reader.pages)}\n"
                summary_text += f"- *Words:* ~{len(content.split()):,}\n"
                summary_text += f"- *Topics:* {', '.join(self.documents[doc_id]['topics'][:5])}\n"
                summary_text += f"- *Summary:* {doc_summary}\n\n"

            # Set first document as active
            if processed_docs:
                self.active_document = processed_docs[0][0]

            status_msg = f"âœ… Successfully processed {len(processed_docs)} documents"
            return status_msg, summary_text

        except Exception as e:
            return f"âŒ Error processing documents: {str(e)}", ""

    def chunk_document(self, content: str, chunk_size: int = 1000) -> List[str]:
        """Split document into manageable chunks for better processing"""
        words = content.split()
        chunks = []

        for i in range(0, len(words), chunk_size):
            chunk = ' '.join(words[i:i + chunk_size])
            chunks.append(chunk)

        return chunks

    def extract_topics(self, content: str) -> List[str]:
        """Extract key topics from document content"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": "Extract 5-10 key topics or subjects from this academic content. Return only topic names separated by commas."
                },
                {
                    "role": "user",
                    "content": f"Extract key topics from this content:\n\n{content[:2000]}"
                }
            ]

            result = self.pipe(messages, max_new_tokens=100, temperature=0.5, do_sample=True)
            topics_text = self.extract_response(result)

            # Clean and parse topics
            topics = [topic.strip() for topic in topics_text.split(',') if topic.strip()]
            return topics[:10]  # Limit to 10 topics

        except Exception as e:
            return ["General Study Material"]

    def generate_document_summary(self, content: str, title: str) -> str:
        """Generate advanced document summary"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": "Create a concise academic summary focusing on key concepts, learning objectives, and main topics. Keep it under 100 words."
                },
                {
                    "role": "user",
                    "content": f"Summarize this academic document '{title}':\n\n{content[:3000]}"
                }
            ]

            result = self.pipe(messages, max_new_tokens=150, temperature=0.6, do_sample=True)
            return self.extract_response(result)

        except Exception as e:
            return "Summary unavailable"

    def intelligent_qa(self, question: str, history: List[Tuple[str, str]],
                      context_mode: str = "smart") -> Tuple[str, List[Tuple[str, str]]]:
        """Advanced Q&A with intelligent context selection"""
        if not question.strip():
            return "", history

        if not self.documents:
            response = "ğŸ“š Please upload PDF documents first to start your study session!"
            history.append((question, response))
            return "", history

        start_time = time.time()

        try:
            # Analyze question type and difficulty
            question_type = self.analyze_question_type(question)
            self.question_types[question_type] += 1

            # Smart context selection
            relevant_content = self.select_relevant_content(question, context_mode)

            # Build enhanced context
            context = self.build_enhanced_context(question, relevant_content, history)

            # Generate response based on question type
            response = self.generate_contextual_response(question, context, question_type)

            # Update learning analytics
            self.update_learning_progress(question, question_type)

            # Track response time
            response_time = time.time() - start_time
            self.response_times.append(response_time)

            # Store question in history
            self.question_history.append({
                'question': question,
                'response': response,
                'timestamp': datetime.now(),
                'type': question_type,
                'response_time': response_time
            })

            history.append((question, response))
            return "", history

        except Exception as e:
            error_response = f"âŒ Error processing question: {str(e)}"
            history.append((question, error_response))
            return "", history

    def analyze_question_type(self, question: str) -> str:
        """Analyze the type of question being asked"""
        question_lower = question.lower()

        if any(word in question_lower for word in ['what is', 'define', 'definition', 'meaning']):
            return "definition"
        elif any(word in question_lower for word in ['how', 'explain', 'describe', 'process']):
            return "explanation"
        elif any(word in question_lower for word in ['why', 'reason', 'cause', 'because']):
            return "reasoning"
        elif any(word in question_lower for word in ['compare', 'difference', 'versus', 'vs']):
            return "comparison"
        elif any(word in question_lower for word in ['example', 'instances', 'cases']):
            return "examples"
        elif any(word in question_lower for word in ['summary', 'summarize', 'overview']):
            return "summary"
        elif '?' in question and any(word in question_lower for word in ['quiz', 'test', 'question']):
            return "assessment"
        else:
            return "general"

    def select_relevant_content(self, question: str, mode: str = "smart") -> str:
        """Select most relevant content based on question"""
        if not self.active_document or self.active_document not in self.documents:
            if self.documents:
                self.active_document = list(self.documents.keys())[0]
            else:
                return ""

        doc = self.documents[self.active_document]

        if mode == "full":
            return doc['content'][:5000]  # Full document (limited)
        elif mode == "smart":
            # Find most relevant chunks based on keyword matching
            question_words = set(question.lower().split())
            chunk_scores = []

            for i, chunk in enumerate(doc['chunks']):
                chunk_words = set(chunk.lower().split())
                score = len(question_words.intersection(chunk_words))
                chunk_scores.append((score, i, chunk))

            # Select top 3 relevant chunks
            chunk_scores.sort(reverse=True)
            relevant_chunks = [chunk for _, _, chunk in chunk_scores[:3]]
            return '\n\n'.join(relevant_chunks)
        else:
            return doc['content'][:3000]  # Default mode

    def build_enhanced_context(self, question: str, content: str, history: List[Tuple[str, str]]) -> str:
        """Build enhanced context with metadata and history"""
        context = f"Study Material: {self.documents[self.active_document]['title']}\n\n"
        context += f"Content:\n{content}\n\n"

        # Add relevant conversation history
        if history and len(history) > 0:
            context += "Recent Discussion:\n"
            for q, a in history[-2:]:  # Last 2 exchanges
                context += f"Q: {q}\nA: {a}\n"
            context += "\n"

        # Add learning context if available
        if hasattr(self, 'current_topic'):
            context += f"Current Focus Topic: {self.current_topic}\n"

        return context

    def generate_contextual_response(self, question: str, context: str, question_type: str) -> str:
        """Generate response tailored to question type"""
        system_prompts = {
            "definition": "You are an academic tutor specializing in clear definitions. Provide precise, educational definitions with context.",
            "explanation": "You are an educational expert. Explain concepts step-by-step with examples and clarity.",
            "reasoning": "You are a critical thinking tutor. Explain the 'why' behind concepts with logical reasoning.",
            "comparison": "You are a comparative analysis expert. Highlight key differences and similarities clearly.",
            "examples": "You are an example-focused tutor. Provide concrete, relevant examples to illustrate concepts.",
            "summary": "You are a summarization expert. Create comprehensive yet concise summaries.",
            "assessment": "You are a testing expert. Create educational assessments that test understanding.",
            "general": "You are a comprehensive academic tutor. Provide thorough, educational responses."
        }

        try:
            messages = [
                {
                    "role": "system",
                    "content": system_prompts.get(question_type, system_prompts["general"])
                },
                {
                    "role": "user",
                    "content": f"Context: {context}\n\nStudent Question: {question}\n\nProvide a clear, educational response:"
                }
            ]

            result = self.pipe(messages, max_new_tokens=600, temperature=0.7, do_sample=True)
            response = self.extract_response(result)

            # Add appropriate emoji based on question type
            emoji_map = {
                "definition": "ğŸ“–",
                "explanation": "ğŸ”",
                "reasoning": "ğŸ¤”",
                "comparison": "âš–",
                "examples": "ğŸ’¡",
                "summary": "ğŸ“‹",
                "assessment": "ğŸ§ ",
                "general": "ğŸ“"
            }

            return f"{emoji_map.get(question_type, 'ğŸ“')} {response}"

        except Exception as e:
            return f"âŒ Error generating response: {str(e)}"

    def generate_adaptive_quiz(self, difficulty: str, num_questions: int) -> str:
        """Generate adaptive quiz based on learning progress"""
        if not self.documents:
            return "âŒ Please upload documents first."

        try:
            # Determine content based on weak areas and progress
            weak_topics = self.identify_weak_areas()
            content = self.select_relevant_content("", "smart")

            difficulty_prompts = {
                "easy": "Create basic recall and recognition questions",
                "medium": "Create application and analysis questions",
                "hard": "Create synthesis and evaluation questions",
                "adaptive": f"Create mixed difficulty questions focusing on: {', '.join(weak_topics[:3])}"
            }

            messages = [
                {
                    "role": "system",
                    "content": f"You are an adaptive quiz generator. {difficulty_prompts.get(difficulty, difficulty_prompts['medium'])}. Format questions clearly with numbers."
                },
                {
                    "role": "user",
                    "content": f"Generate {num_questions} quiz questions from this content:\n\n{content[:4000]}\n\nDifficulty: {difficulty}"
                }
            ]

            result = self.pipe(messages, max_new_tokens=800, temperature=0.8, do_sample=True)
            quiz_content = self.extract_response(result)

            # Store quiz for later analysis
            quiz_id = hashlib.md5(f"{quiz_content}{time.time()}".encode()).hexdigest()[:8]
            self.quiz_bank[quiz_id] = {
                'content': quiz_content,
                'difficulty': difficulty,
                'timestamp': datetime.now(),
                'document': self.active_document
            }

            return f"ğŸ§  *Adaptive Quiz - {difficulty.title()} Level*\n\n{quiz_content}"

        except Exception as e:
            return f"âŒ Error generating quiz: {str(e)}"

    def generate_study_plan(self, duration_days: int, focus_areas: str) -> str:
        """Generate personalized study plan"""
        if not self.documents:
            return "âŒ Please upload study materials first."

        try:
            doc_titles = [doc['title'] for doc in self.documents.values()]
            weak_areas = self.identify_weak_areas()

            messages = [
                {
                    "role": "system",
                    "content": f"You are a study plan expert. Create a {duration_days}-day structured study plan with daily goals, activities, and progress milestones."
                },
                {
                    "role": "user",
                    "content": f"Create a study plan for these materials: {', '.join(doc_titles)}\nFocus areas: {focus_areas}\nWeak areas to improve: {', '.join(weak_areas[:3])}\nDuration: {duration_days} days"
                }
            ]

            result = self.pipe(messages, max_new_tokens=600, temperature=0.6, do_sample=True)
            study_plan = self.extract_response(result)

            return f"ğŸ“… *Personalized {duration_days}-Day Study Plan*\n\n{study_plan}"

        except Exception as e:
            return f"âŒ Error generating study plan: {str(e)}"

    def identify_weak_areas(self) -> List[str]:
        """Identify areas where student needs more practice"""
        if not self.question_history:
            return []

        # Analyze question patterns and difficulty
        weak_topics = []
        topic_performance = defaultdict(list)

        for q_data in self.question_history[-20:]:  # Recent 20 questions
            question_type = q_data.get('type', 'general')
            response_time = q_data.get('response_time', 0)

            # Consider slow response times as potential weak areas
            if response_time > 5:  # Slow response
                topic_performance[question_type].append(0)
            else:
                topic_performance[question_type].append(1)

        # Calculate performance scores
        for topic, scores in topic_performance.items():
            if scores and sum(scores) / len(scores) < 0.7:  # Less than 70% performance
                weak_topics.append(topic)

        return weak_topics[:5]  # Top 5 weak areas

    def get_learning_analytics(self) -> str:
        """Generate comprehensive learning analytics"""
        try:
            if not self.question_history:
                return "ğŸ“Š *Learning Analytics*\n\nNo study session data available yet. Start asking questions to see your progress!"

            total_questions = len(self.question_history)
            avg_response_time = np.mean(self.response_times) if self.response_times else 0

            # Question type distribution
            type_stats = dict(self.question_types.most_common())

            # Recent performance trends
            recent_sessions = len([q for q in self.question_history if
                                 (datetime.now() - q['timestamp']).days <= 7])

            # Weak areas
            weak_areas = self.identify_weak_areas()

            analytics = f"""ğŸ“Š *Learning Analytics Dashboard*

### ğŸ“ˆ Study Statistics
- *Total Questions Asked*: {total_questions}
- *Average Response Time*: {avg_response_time:.1f} seconds
- *Recent Session Activity*: {recent_sessions} questions this week
- *Documents Processed*: {len(self.documents)}

### ğŸ¯ Question Type Distribution
"""

            for q_type, count in type_stats.items():
                percentage = (count / total_questions) * 100
                analytics += f"- *{q_type.title()}*: {count} ({percentage:.1f}%)\n"

            analytics += f"""
### âš  Areas for Improvement
{f"- {chr(10).join(['- ' + area.title() for area in weak_areas])}" if weak_areas else "- Great job! No weak areas identified"}

### ğŸ“ Study Recommendations
- Focus more on {weak_areas[0] if weak_areas else 'advanced concepts'}
- {"Increase study frequency" if recent_sessions < 5 else "Maintain current study pace"}
- Try adaptive quizzes to test understanding
"""

            return analytics

        except Exception as e:
            return f"âŒ Error generating analytics: {str(e)}"

    def extract_response(self, result) -> str:
        """Enhanced response extraction with better parsing"""
        try:
            if isinstance(result, list) and len(result) > 0:
                generated = result[0].get('generated_text', '')

                if isinstance(generated, list):
                    # Find assistant response
                    for msg in generated:
                        if isinstance(msg, dict) and msg.get('role') == 'assistant':
                            return msg.get('content', 'No response generated.')
                    return "No response generated."

                elif isinstance(generated, str):
                    # Clean up the response
                    lines = generated.split('\n')
                    cleaned_lines = []

                    for line in lines:
                        # Skip system/user prefixes
                        if not any(prefix in line.lower() for prefix in ['system:', 'user:', 'assistant:']):
                            cleaned_lines.append(line)

                    response = '\n'.join(cleaned_lines).strip()
                    return response if response else "No response generated."
                else:
                    return str(generated)

            return "No response generated."

        except Exception as e:
            return f"Error processing response: {str(e)}"

    def update_learning_progress(self, question: str, question_type: str):
        """Update learning progress tracking"""
        self.topics_studied[question_type] += 1

        # Simple progress tracking
        if question_type not in self.learning_progress:
            self.learning_progress[question_type] = {
                'attempts': 0,
                'avg_time': 0,
                'difficulty': 'medium'
            }

        self.learning_progress[question_type]['attempts'] += 1


    def clear_all_data(self):
        """Clear all session data"""
        self.documents.clear()
        self.active_document = None
        self.question_history.clear()
        self.learning_progress.clear()
        self.weak_areas.clear()

        return [], "", "", "", "", ""


def create_advanced_student_app():
    """Create advanced Gradio interface"""
    qa_system = AdvancedStudentPDFQA()

    # Advanced CSS styling
    custom_css = """
    .gradio-container {
        font-family: 'Inter', 'Segoe UI', sans-serif;
        max-width: 1400px;
        margin: 0 auto;
    }
    .advanced-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 30px;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 25px;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
    }
    .feature-card {
        background: linear-gradient(145deg, #f0f2f5, #ffffff);
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
    }
    .metric-card {
        background: linear-gradient(45deg, #4facfe, #00f2fe);
        color: white;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
        margin: 5px;
    }
    """

    with gr.Blocks(title="ğŸ“ Advanced AI Study System", theme=gr.themes.Soft(), css=custom_css) as demo:

        gr.HTML("""
        <div class="advanced-header">
            <h1>ğŸš€ Advanced AI-Powered Study System</h1>
            <p>Intelligent PDF Analysis â€¢ Adaptive Learning â€¢ Progress Tracking â€¢ Personalized Study Plans</p>
            <p><strong>Powered by IBM Granite 3.3B AI Model</strong></p>
        </div>
        """)

        with gr.Tab("ğŸ“š Document Management"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“ Multi-Document Upload")
                    file_input = gr.File(
                        label="Upload Multiple PDFs",
                        file_count="multiple",
                        file_types=[".pdf"],
                        type="filepath"
                    )
                    process_btn = gr.Button("ğŸ”„ Process All Documents", variant="primary", size="lg")

                    doc_status = gr.Textbox(
                        label="Processing Status",
                        interactive=False,
                        lines=3
                    )

                    gr.Markdown("### âš™ Study Configuration")
                    context_mode = gr.Radio(
                        choices=["smart", "full", "focused"],
                        value="smart",
                        label="Context Selection Mode"
                    )

                with gr.Column(scale=2):
                    gr.Markdown("### ğŸ“– Document Library Overview")
                    library_summary = gr.Textbox(
                        label="Document Summaries",
                        lines=20,
                        interactive=False,
                        placeholder="Upload documents to see intelligent summaries and analysis..."
                    )

        with gr.Tab("ğŸ§  Intelligent Q&A"):
            with gr.Row():
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(
                        label="ğŸ“ Advanced AI Study Assistant",
                        height=600,
                        placeholder="Welcome to your advanced study companion! Upload documents and ask intelligent questions about your study materials."
                    )

                    with gr.Row():
                        question_input = gr.Textbox(
                            label="Ask Your Question",
                            placeholder="Explain the relationship between quantum mechanics and classical physics...",
                            scale=4
                        )
                        ask_btn = gr.Button("ğŸš€ Ask", variant="primary", scale=1)

                    with gr.Row():
                        gr.Markdown("### ğŸ¯ Smart Question Templates")

                    with gr.Row():
                        explain_btn = gr.Button("ğŸ” Deep Explanation")
                        compare_btn = gr.Button("âš– Compare Concepts")
                        examples_btn = gr.Button("ğŸ’¡ Show Examples")
                        analyze_btn = gr.Button("ğŸ§ª Critical Analysis")

                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“Š Session Analytics")
                    session_stats = gr.HTML("""
                    <div class="feature-card">
                        <h4>ğŸ“ˆ Current Session</h4>
                        <p>Questions Asked: 0</p>
                        <p>Topics Covered: 0</p>
                        <p>Average Response Time: 0s</p>
                    </div>
                    """)

                    gr.Markdown("### ğŸ¯ Quick Actions")
                    bookmark_btn = gr.Button("ğŸ”– Bookmark Response", size="sm")
                    summarize_btn = gr.Button("ğŸ“‹ Summarize Session", size="sm")
                    clear_btn = gr.Button("ğŸ—‘ Clear Chat", variant="secondary", size="sm")

        with gr.Tab("ğŸ“ Adaptive Assessment"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ§  Intelligent Quiz Generator")

                    with gr.Row():
                        difficulty_level = gr.Radio(
                            choices=["easy", "medium", "hard", "adaptive"],
                            value="adaptive",
                            label="Difficulty Level"
                        )
                        num_questions = gr.Slider(
                            minimum=3,
                            maximum=15,
                            value=7,
                            step=1,
                            label="Number of Questions"
                        )

                    generate_quiz_btn = gr.Button("ğŸ¯ Generate Adaptive Quiz", variant="primary")

                    quiz_output = gr.Textbox(
                        label="Generated Assessment",
                        lines=18,
                        interactive=False,
                        placeholder="Click 'Generate Adaptive Quiz' to create personalized questions based on your learning progress..."
                    )

                with gr.Column():
                    gr.Markdown("### ğŸ“Š Performance Analytics")
                    analytics_btn = gr.Button("ğŸ“ˆ Generate Analytics Report", variant="secondary")

                    analytics_output = gr.Textbox(
                        label="Learning Analytics",
                        lines=18,
                        interactive=False,
                        placeholder="Your detailed learning analytics will appear here..."
                    )

        with gr.Tab("ğŸ“… Study Planning"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ¯ Personalized Study Plan Generator")

                    study_duration = gr.Slider(
                        minimum=3,
                        maximum=30,
                        value=14,
                        step=1,
                        label="Study Plan Duration (Days)"
                    )

                    focus_areas = gr.Textbox(
                        label="Focus Areas (comma-separated)",
                        placeholder="quantum physics, thermodynamics, electromagnetic theory",
                        value=""
                    )

                    study_intensity = gr.Radio(
                        choices=["light", "moderate", "intensive"],
                        value="moderate",
                        label="Study Intensity"
                    )

                    generate_plan_btn = gr.Button("ğŸ“… Generate Study Plan", variant="primary")

                with gr.Column():
                    study_plan_output = gr.Textbox(
                        label="Personalized Study Plan",
                        lines=20,
                        interactive=False,
                        placeholder="Your AI-generated study plan will appear here with daily goals and milestones..."
                    )

        with gr.Tab("ğŸ“Š Advanced Analytics"):
            gr.Markdown("### ğŸ“ Comprehensive Learning Dashboard")

            with gr.Row():
                with gr.Column():
                    refresh_analytics_btn = gr.Button("ğŸ”„ Refresh Analytics", variant="primary")
                    export_data_btn = gr.Button("ğŸ’¾ Export Study Data", variant="secondary")

                with gr.Column():
                    reset_progress_btn = gr.Button("ğŸ”„ Reset All Progress", variant="stop")

            detailed_analytics = gr.Textbox(
                label="Detailed Learning Analytics",
                lines=25,
                interactive=False,
                placeholder="Comprehensive analytics including progress tracking, weak areas identification, and study recommendations will appear here..."
            )

        with gr.Tab("â„¹ Advanced Guide"):
            gr.Markdown("""
            ## ğŸš€ Advanced AI Study System Guide

            ### ğŸ¯ Key Features

            #### ğŸ“š *Multi-Document Intelligence*
            - Upload multiple PDFs simultaneously
            - Intelligent content analysis and topic extraction
            - Cross-document knowledge synthesis
            - Smart context selection for better answers

            #### ğŸ§  *Adaptive Learning Engine*
            - AI-powered question type analysis
            - Personalized difficulty adjustment
            - Weak area identification and targeted practice
            - Progress tracking and performance analytics

            #### ğŸ“Š *Advanced Analytics*
            - Real-time learning progress monitoring
            - Question type distribution analysis
            - Response time optimization
            - Identification of weak areas
            - Personalized study recommendations

            #### ğŸ“… *Personalized Study Planning*
            - Generate structured study plans based on your documents and goals
            - Set duration and focus areas
            - Get daily goals and milestones

            ### ğŸ’¡ How to Use Advanced Features

            1. *Upload Documents*: Go to 'Document Management', upload your PDFs, and click 'Process All Documents'.
            2. *Intelligent Q&A*: Ask complex questions about your materials in the 'Intelligent Q&A' tab. The AI will use relevant context from your uploaded documents.
            3. *Adaptive Quiz*: Test your knowledge with personalized quizzes in the 'Adaptive Assessment' tab. The difficulty can adapt to your performance.
            4. *Study Planning*: Generate a structured study plan in the 'Study Planning' tab based on your documents and goals.
            5. *View Analytics*: See detailed insights into your learning progress in the 'Advanced Analytics' tab.

            ### ğŸ”§ Tips for Best Results

            - *Clear Questions*: Formulate clear and specific questions for better responses.
            - *Multiple Documents*: Upload related documents to enable cross-referencing.
            - *Use Templates*: Utilize the 'Smart Question Templates' for common query types.
            - *Check Analytics*: Regularly review your analytics to identify areas needing more focus.

            """)

        # Event handlers (ensure these are correctly matched to your UI elements)
        process_btn.click(
            fn=qa_system.upload_multiple_documents,
            inputs=[file_input],
            outputs=[doc_status, library_summary]
        )

        # Q&A handlers
        ask_btn.click(
            fn=qa_system.intelligent_qa,
            inputs=[question_input, chatbot, context_mode],
            outputs=[question_input, chatbot]
        )
        question_input.submit(
            fn=qa_system.intelligent_qa,
            inputs=[question_input, chatbot, context_mode],
            outputs=[question_input, chatbot]
        )

        # Smart Question Templates handlers
        explain_btn.click(
            fn=lambda h: qa_system.intelligent_qa("Provide a detailed explanation of the key concepts.", h),
            inputs=[chatbot],
            outputs=[question_input, chatbot]
        )
        compare_btn.click(
            fn=lambda h: qa_system.intelligent_qa("Compare and contrast [Concept 1] and [Concept 2].", h),
            inputs=[chatbot],
            outputs=[question_input, chatbot]
        )
        examples_btn.click(
            fn=lambda h: qa_system.intelligent_qa("Give examples to illustrate [Concept].", h),
            inputs=[chatbot],
            outputs=[question_input, chatbot]
        )
        analyze_btn.click(
            fn=lambda h: qa_system.intelligent_qa("Provide a critical analysis of [Topic/Argument].", h),
            inputs=[chatbot],
            outputs=[question_input, chatbot]
        )


        # Assessment handlers
        generate_quiz_btn.click(
            fn=qa_system.generate_adaptive_quiz,
            inputs=[difficulty_level, num_questions],
            outputs=[quiz_output]
        )

        analytics_btn.click(
            fn=qa_system.get_learning_analytics,
            inputs=[],
            outputs=[analytics_output]
        )

        # Study Planning handlers
        generate_plan_btn.click(
            fn=qa_system.generate_study_plan,
            inputs=[study_duration, focus_areas],
            outputs=[study_plan_output]
        )

        # Advanced Analytics handlers
        refresh_analytics_btn.click(
            fn=qa_system.get_learning_analytics,
            inputs=[],
            outputs=[detailed_analytics]
        )

        reset_progress_btn.click(
            fn=qa_system.clear_all_data,
            inputs=[],
            outputs=[chatbot, doc_status, library_summary, quiz_output, analytics_output, detailed_analytics]
        )

        # Quick Actions handlers
        clear_btn.click(
            fn=lambda: [],
            outputs=[chatbot]
        )
        # Note: Bookmark and Summarize Session buttons would require additional logic to implement fully.

    return demo

if __name__ == "__main__":
    # Launch the advanced student study assistant
    print("ğŸš€ Launching Advanced AI Study System...")
    demo = create_advanced_student_app()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # Set to True for public sharing
        debug=True
    )

